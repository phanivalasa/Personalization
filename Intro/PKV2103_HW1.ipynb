{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Phani Valasa <br />\n",
    "**UNI  :** PKV2103 <br />\n",
    "**Sub.:** Personalization Course; Homework 1; Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this exercise we will try to predict the subjective quality of Portuguese red wine using only the physiochemical properties of each wine. We will not use any the common regression methods and packages for Python or R - instead we will use minimization methods in order to minimize the error of a linear model. In this case, we will define error as Residual Sum of Squares (RSS), which is also often known as Squared Error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# Read the input training set\n",
    "data = pd.read_csv('winequality-red.csv',sep=';')\n",
    "X = data[data.columns[:-1]]\n",
    "y = data[['quality']]\n",
    "\n",
    "# Now split the dataset into training and test data and convert them to arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_y(X, beta):\n",
    "    y_hat = np.dot(X, beta)\n",
    "    return y_hat.reshape(y_hat.shape[0],1)\n",
    "\n",
    "def RSS(beta,X, y):\n",
    "    y_hat = compute_y(X, beta)\n",
    "    rss = np.sum((y-y_hat)**2)\n",
    "    return rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of RSS on Training and Test Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares on Training data is  550.97\n",
      "Residual sum of squares on Test data is  117.15\n"
     ]
    }
   ],
   "source": [
    "beta0 = np.random.normal(0, 1, X_train.shape[1])\n",
    "res = minimize(fun=RSS, x0=beta0, args=(X_train,y_train))\n",
    "beta_hat = res.x\n",
    "\n",
    "train_RSS = RSS(beta_hat,X_train,y_train)\n",
    "print \"Residual sum of squares on Training data is \" , round(train_RSS,2)\n",
    "test_RSS = RSS(beta_hat,X_test,y_test)\n",
    "print \"Residual sum of squares on Test data is \", round(test_RSS,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance and Magnitude of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity :   -0.0152 ;   Average:  8.3196372733\n",
      "volatile acidity :   -1.1808 ;   Average:  0.527820512821\n",
      "citric acid :   -0.1422 ;   Average:  0.270975609756\n",
      "residual sugar :   0.0092 ;   Average:  2.53880550344\n",
      "chlorides :   -2.0521 ;   Average:  0.0874665415885\n",
      "free sulfur dioxide :   0.0036 ;   Average:  15.8749218261\n",
      "total sulfur dioxide :   -0.0031 ;   Average:  46.4677923702\n",
      "density :   5.1195 ;   Average:  0.996746679174\n",
      "pH :   -0.6295 ;   Average:  3.31111319575\n",
      "sulphates :   0.8344 ;   Average:  0.658148843027\n",
      "alcohol :   0.2972 ;   Average:  10.4229831144\n"
     ]
    }
   ],
   "source": [
    "column_list = X.columns.values\n",
    "for i in range(len(list(column_list))) :\n",
    "    print column_list[i],\":  \", round(beta_hat[i],4), \";   Average: \", X[column_list[i]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSS for different values of beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS for different values of beta:  117.15 117.15 117.15\n"
     ]
    }
   ],
   "source": [
    "beta1=list(range(4,15))\n",
    "beta2=list(range(51,40,-1))\n",
    "beta3=list(range(1100,1111))\n",
    "\n",
    "res1 = minimize(fun=RSS, x0=beta1, args=(X_train,y_train))\n",
    "beta_hat1 = res1.x\n",
    "test_RSS1 = RSS(beta_hat1,X_test,y_test)\n",
    "\n",
    "res2 = minimize(fun=RSS, x0=beta2, args=(X_train,y_train))\n",
    "beta_hat2 = res2.x\n",
    "test_RSS2 = RSS(beta_hat2,X_test,y_test)\n",
    "\n",
    "res3 = minimize(fun=RSS, x0=beta3, args=(X_train,y_train))\n",
    "beta_hat3 = res3.x\n",
    "test_RSS3 = RSS(beta_hat3,X_test,y_test)\n",
    "\n",
    "print \"RSS for different values of beta: \",round(test_RSS1,2), round(test_RSS2,2), round(test_RSS3,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSS for different Solver Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver Method : Nelder-Mead ; RSS Value: 162.38\n",
      "Solver Method : Powell ; RSS Value: 121.31\n",
      "Solver Method : CG ; RSS Value: 117.06\n",
      "Solver Method : BFGS ; RSS Value: 117.15\n",
      "Solver Method : L-BFGS-B ; RSS Value: 117.09\n",
      "Solver Method : TNC ; RSS Value: 321.11\n",
      "Solver Method : COBYLA ; RSS Value: 577.0\n",
      "Solver Method : SLSQP ; RSS Value: 117.15\n"
     ]
    }
   ],
   "source": [
    "def RSS_Solver(beta, X_train, y_train, X_test, y_test, solver) :\n",
    "    res = minimize(fun=RSS, x0=beta, method=solver, args=(X_train,y_train))\n",
    "    beta_hat = res.x\n",
    "    test_RSS = RSS(beta_hat,X_test,y_test)\n",
    "    return test_RSS\n",
    "    \n",
    "solver_methods = ['Nelder-Mead', 'Powell', 'CG', 'BFGS', 'L-BFGS-B', 'TNC', 'COBYLA', 'SLSQP']\n",
    "\n",
    "for i in range(len(solver_methods)):\n",
    "    rss_test = RSS_Solver(beta0, X_train, y_train, X_test, y_test, solver_methods[i])\n",
    "    print \"Solver Method :\", solver_methods[i], \"; RSS Value:\" , round(rss_test,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **What are the qualitative results from your model? Which features seem to be most important? Do you think that the magnitude of the features in X may affect the results (for example, the average total sulfur dioxide across all wines is 46.47, but the average chlorides is only 0.087).**\n",
    " \n",
    "  *Density has the highest coefficient value, which seems to indicate it is the most important feature. As the value of desity increase, it more likely to be of high quality. The magnitude of the features in X has a direct impact on the coefficients and so coefficients cannot be directly compared to understand feature importance. When magnitudes of features hugely vary, it'll help to do some standardizing of the data in pre-processing for coefficient comparision*\n",
    "\n",
    "\n",
    " * **How well does your model fit? You should be able to measure the goodness of fit, RSS, on both the training data and the test data, but only report the results on the test data. In Machine Learning we almost always only care about how well the model fits on data that has not been used to fit the model, because we need to use the model in the future, not the past. Therefore, we only report performance with holdout data, or test data.**\n",
    " \n",
    "  *RSS on the training data is 550.97. And RSS on the test data is 117.15. RSS is a measure of the discrepancy between the data and an estimation model. A small RSS indicates a tight fit of the model to the data. It is used as an optimality criterion in parameter selection and model selection*\n",
    "  \n",
    "  \n",
    " * **Does the end result or RSS change if you try different initial values of β? What happens if you change the magnitude of the initial β?**\n",
    " \n",
    "  *The end result of RSS has not changed for the different values of β used. However as the magnitude of β increase, it takes longer to converge at the optimal β*\n",
    "\n",
    "\n",
    " * **Does the choice of solver method change the end result or RSS?**\n",
    " \n",
    "  *Solver Methods does change the end result of RSS. In this particular case, CG has an optimal value.*\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing the Model; lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Model: L2 Residual sum of squares on Training data is  550.98\n",
      "Regularized Model: L2 Residual sum of squares on Test data is  117.07\n"
     ]
    }
   ],
   "source": [
    "def RSS_reg_l2(beta,X, y,lamda):\n",
    "    y_hat = compute_y(X, beta)\n",
    "    rss_reg_l2 = np.sum((y - y_hat) ** 2) + (lamda * np.sum(beta**2))\n",
    "    return rss_reg_l2\n",
    "\n",
    "def RSS_reg_l1(beta,X, y,lamda):\n",
    "    y_hat = compute_y(X, beta)\n",
    "    rss_reg_l1 = np.sum((y - y_hat) ** 2) + (lamda * np.sum(np.abs(beta)))\n",
    "    return rss_reg_l1\n",
    "\n",
    "def RSS_reg(beta, X_train, y_train, X_test, y_test, reg,lamda) :\n",
    "    if reg==\"l2\":\n",
    "        res = minimize(fun=RSS_reg_l2, x0=beta, args=(X_train,y_train, lamda))\n",
    "        beta_hat_l2 = res.x\n",
    "        test_RSS = RSS(beta_hat_l2,X_test,y_test)\n",
    "    elif reg==\"l1\":\n",
    "        res = minimize(fun=RSS_reg_l1, x0=beta, args=(X_train,y_train,lamda))\n",
    "        beta_hat_l1 = res.x\n",
    "        test_RSS = RSS(beta_hat_l1,X_test,y_test)            \n",
    "    return test_RSS\n",
    "\n",
    "train_RSS_Reg_L2 = RSS_reg(beta0, X_train, y_train, X_train, y_train, \"l2\",0.01)\n",
    "test_RSS_Reg_L2 = RSS_reg(beta0, X_train, y_train, X_test, y_test, \"l2\",0.01)\n",
    "\n",
    "print \"Regularized Model: L2 Residual sum of squares on Training data is \", round(train_RSS_Reg_L2,2)\n",
    "print \"Regularized Model: L2 Residual sum of squares on Test data is \", round(test_RSS_Reg_L2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different values of Lamda & Training RSS; L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda :  0 ; L2 RSS (Train):  550.973\n",
      "Lambda :  0.01 ; L2 RSS (Train):  550.9768\n",
      "Lambda :  0.02 ; L2 RSS (Train):  550.9878\n",
      "Lambda :  0.03 ; L2 RSS (Train):  551.0055\n",
      "Lambda :  0.04 ; L2 RSS (Train):  551.0294\n",
      "Lambda :  0.05 ; L2 RSS (Train):  551.0589\n",
      "Lambda :  0.06 ; L2 RSS (Train):  551.0938\n",
      "Lambda :  0.07 ; L2 RSS (Train):  551.1336\n",
      "Lambda :  0.08 ; L2 RSS (Train):  551.1779\n",
      "Lambda :  0.09 ; L2 RSS (Train):  551.2263\n",
      "Lambda :  0.1 ; L2 RSS (Train):  551.2787\n",
      "Lambda :  0.2 ; L2 RSS (Train):  551.9583\n",
      "Lambda :  0.3 ; L2 RSS (Train):  552.7979\n",
      "Lambda :  0.4 ; L2 RSS (Train):  553.6912\n",
      "Lambda :  0.5 ; L2 RSS (Train):  554.5842\n",
      "Lambda :  1 ; L2 RSS (Train):  558.4808\n",
      "Lambda :  10 ; L2 RSS (Train):  576.3298\n",
      "Lambda :  20 ; L2 RSS (Train):  584.7542\n",
      "Lambda :  30 ; L2 RSS (Train):  591.5533\n",
      "Lambda :  40 ; L2 RSS (Train):  597.29\n",
      "Lambda :  50 ; L2 RSS (Train):  602.1947\n"
     ]
    }
   ],
   "source": [
    "lamda_reg = [0,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2,0.3,0.4,0.5,1,10,20,30,40,50]\n",
    "\n",
    "for i in range(len(lamda_reg)):\n",
    "    train_RSS_Reg_L2 = 0\n",
    "    train_RSS_Reg_L2 = RSS_reg(beta0, X_train, y_train, X_train, y_train , \"l2\", lamda_reg[i])  \n",
    "    print \"Lambda : \", lamda_reg[i], \"; L2 RSS (Train): \", round(train_RSS_Reg_L2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Values of Lamda & Test RSS ; L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda :  0 ; L2 RSS (Test):  117.149\n",
      "Lambda :  0.01 ; L2 RSS (Test):  117.066\n",
      "Lambda :  0.02 ; L2 RSS (Test):  116.987\n",
      "Lambda :  0.03 ; L2 RSS (Test):  116.911\n",
      "Lambda :  0.04 ; L2 RSS (Test):  116.839\n",
      "Lambda :  0.05 ; L2 RSS (Test):  116.771\n",
      "Lambda :  0.06 ; L2 RSS (Test):  116.705\n",
      "Lambda :  0.07 ; L2 RSS (Test):  116.643\n",
      "Lambda :  0.08 ; L2 RSS (Test):  116.583\n",
      "Lambda :  0.09 ; L2 RSS (Test):  116.526\n",
      "Lambda :  0.1 ; L2 RSS (Test):  116.471\n",
      "Lambda :  0.2 ; L2 RSS (Test):  116.037\n",
      "Lambda :  0.3 ; L2 RSS (Test):  115.75\n",
      "Lambda :  0.4 ; L2 RSS (Test):  115.556\n",
      "Lambda :  0.5 ; L2 RSS (Test):  115.422\n",
      "Lambda :  1 ; L2 RSS (Test):  115.167\n",
      "Lambda :  10 ; L2 RSS (Test):  115.257\n",
      "Lambda :  20 ; L2 RSS (Test):  115.657\n",
      "Lambda :  30 ; L2 RSS (Test):  116.192\n",
      "Lambda :  40 ; L2 RSS (Test):  116.737\n",
      "Lambda :  50 ; L2 RSS (Test):  117.252\n"
     ]
    }
   ],
   "source": [
    "lamda_reg = [0,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2,0.3,0.4,0.5,1,10,20,30,40,50]\n",
    "\n",
    "for i in range(len(lamda_reg)):\n",
    "    test_RSS_Reg_L2 = 0\n",
    "    test_RSS_Reg_L2 = RSS_reg(beta0, X_train, y_train, X_test, y_test , \"l2\", lamda_reg[i])  \n",
    "    print \"Lambda : \", lamda_reg[i], \"; L2 RSS (Test): \", round(test_RSS_Reg_L2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda :  0 ; L1 RSS (Train):  550.973\n",
      "Lambda :  0.01 ; L1 RSS (Train):  550.9731\n",
      "Lambda :  0.02 ; L1 RSS (Train):  550.9733\n",
      "Lambda :  0.03 ; L1 RSS (Train):  550.9736\n",
      "Lambda :  0.04 ; L1 RSS (Train):  550.9741\n",
      "Lambda :  0.05 ; L1 RSS (Train):  550.9748\n",
      "Lambda :  0.06 ; L1 RSS (Train):  550.9756\n",
      "Lambda :  0.07 ; L1 RSS (Train):  550.9765\n",
      "Lambda :  0.08 ; L1 RSS (Train):  550.9776\n",
      "Lambda :  0.09 ; L1 RSS (Train):  550.9788\n",
      "Lambda :  0.1 ; L1 RSS (Train):  550.9801\n",
      "Lambda :  0.2 ; L1 RSS (Train):  551.0015\n",
      "Lambda :  0.3 ; L1 RSS (Train):  551.0371\n",
      "Lambda :  0.4 ; L1 RSS (Train):  551.087\n",
      "Lambda :  0.5 ; L1 RSS (Train):  551.1512\n",
      "Lambda :  1 ; L1 RSS (Train):  551.6859\n",
      "Lambda :  10 ; L1 RSS (Train):  577.3858\n",
      "Lambda :  20 ; L1 RSS (Train):  584.3097\n",
      "Lambda :  30 ; L1 RSS (Train):  591.7746\n",
      "Lambda :  40 ; L1 RSS (Train):  590.9881\n",
      "Lambda :  50 ; L1 RSS (Train):  615.6613\n"
     ]
    }
   ],
   "source": [
    "lamda_reg = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2,0.3,0.4,0.5,1,10,20,30,40,50]\n",
    "\n",
    "for i in range(len(lamda_reg)):\n",
    "    train_RSS_Reg_L1 = RSS_reg(beta0, X_train, y_train, X_train, y_train, \"l1\", lamda_reg[i])  \n",
    "    print \"Lambda : \", lamda_reg[i], \"; L1 RSS (Train): \", round(train_RSS_Reg_L1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda :  0 ; L1 RSS (Test):  117.1485\n",
      "Lambda :  0.01 ; L1 RSS (Test):  117.1381\n",
      "Lambda :  0.02 ; L1 RSS (Test):  117.1277\n",
      "Lambda :  0.03 ; L1 RSS (Test):  117.1174\n",
      "Lambda :  0.04 ; L1 RSS (Test):  117.1071\n",
      "Lambda :  0.05 ; L1 RSS (Test):  117.0968\n",
      "Lambda :  0.06 ; L1 RSS (Test):  117.0865\n",
      "Lambda :  0.07 ; L1 RSS (Test):  117.0763\n",
      "Lambda :  0.08 ; L1 RSS (Test):  117.0661\n",
      "Lambda :  0.09 ; L1 RSS (Test):  117.056\n",
      "Lambda :  0.1 ; L1 RSS (Test):  117.0458\n",
      "Lambda :  0.2 ; L1 RSS (Test):  116.9462\n",
      "Lambda :  0.3 ; L1 RSS (Test):  116.8497\n",
      "Lambda :  0.4 ; L1 RSS (Test):  116.7562\n",
      "Lambda :  0.5 ; L1 RSS (Test):  116.6659\n",
      "Lambda :  1 ; L1 RSS (Test):  116.2605\n",
      "Lambda :  10 ; L1 RSS (Test):  116.0598\n",
      "Lambda :  20 ; L1 RSS (Test):  115.7155\n",
      "Lambda :  30 ; L1 RSS (Test):  116.7202\n",
      "Lambda :  40 ; L1 RSS (Test):  117.8729\n",
      "Lambda :  50 ; L1 RSS (Test):  119.6407\n"
     ]
    }
   ],
   "source": [
    "lamda_reg = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2,0.3,0.4,0.5,1,10,20,30,40,50]\n",
    "\n",
    "for i in range(len(lamda_reg)):\n",
    "    test_RSS_Reg_L1 = RSS_reg(beta0, X_train, y_train, X_test, y_test, \"l1\", lamda_reg[i])  \n",
    "    print \"Lambda : \", lamda_reg[i], \"; L1 RSS (Test): \", round(test_RSS_Reg_L1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **Try adding in an L2 (aka Ridge) regularization penalty to your model above to create a new, regularized model.  You will need to choose a value of lambda, so start with something small, like 0.01**\n",
    " \n",
    "  *Regularized Model: Created the L2 model and found that at Lamda = 0.01, the Residual sum of squares on Test data is  117.04*\n",
    "\n",
    "\n",
    " * **How does RSS on the training data change? How does RSS on the test data change?**\n",
    " \n",
    "  * For the above code run at Lambda - 0.01, RSS on the training data has increased marginally (i.e., from 550.973 to 550.9768) while the RSS on test data decreased a little (i.e., from 117.149 to 117.066) *\n",
    "  \n",
    "  \n",
    " * **What happens if you try different values of lambda? Can you roughly tune lambda to get the best results on the test data?**\n",
    " \n",
    "  *When different values of Lamdba were tested, the training data RSS has increased with Lambda. Wile the Test data RSS has decresed to a point where RSS is 115.167 for Lambda = 1, and then started to increase indicating the optimum RSS is at the value of Lambda =1*\n",
    "\n",
    "\n",
    " * **Now try using an L1 (aka Lasso) regularization penalty instead. Report your findings on how RSS changes, and if you can roughly tune lambda**\n",
    " \n",
    "  *With L1, RSS on test data has decreased all the way until Lambda = 20 (RSS : 115.7155), and then it started to increase again. The tuned lambda value is 20, which is where there is an optimal RSS value. Please see the output above for more details*\n",
    "\n",
    "\n",
    " * **Again, do you think that the magnitude of the features in X may affect the results with regularization?**\n",
    " \n",
    "  *By introducting the regularization objective function, the beta coefficients are reduced. The magnitube of the features do effect the Coefficients. However Regularization penalizes the huge value of cooefficients to keep the overall objective function minimum. L2 regularization tends to penalize the coefficients with higher values much more than the lower value ones. L1 regularization penalized all of the coefficients equally.*\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
