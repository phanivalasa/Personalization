{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Personalization Project - Part 1 HW2\n",
    "**Team:**  Phani Valasa & Harish Visweswaran \n",
    "\n",
    "**Data Set:**  Taste Profile DataSet by The Echo Nest as part of the Million Song Dataset.\n",
    "\n",
    "### Business Abstract\n",
    "\n",
    "The objective of this Case study is improvise online music provider services. Many of the Music service providers today offer a freemium model with the majority of its users streaming music to their mobiles or desktop via apps or web browsers. Users subscribe for free get ads between tracks which are part of the revenue model. Users of the free service encounter audio ads every five or six songs, or approximately three minutes of advertising for every hour of listening. There are also paid services with uninterrupted streaming.\n",
    "\n",
    "For this business plan to work and remain relevant, it is imperative that right recommendations on songs are provided to users for customer loyalty and stickiness with the app. The problem is more complex than it seems.  Challenges are with the sparse dataset pertaining to user listening and identification of similarities between users, songs and artists.\n",
    "\n",
    "The below case study accesses the data sets available from Kaggle, MSD, LasROSA and Last.fm to evaluate the recommendation models and build a recommendation engine for our Music streaming company.\n",
    "\n",
    "### Objectives and Cosiderations\n",
    "\n",
    "To provide meaningfully relevant Music recommendations for users based on their listening behaviour.\n",
    "\n",
    "We aim to achieve our vision through a systematic process which is given below:\n",
    "\n",
    "* Meaningful: The recommendations have to be something that the user is expected to find useful. Usefulness in this context can have several definitions in terms of genre, artists, region etc. We begin with an assumption that similar people listen to similar songs and hence this similarity becomes a good discriminant for selection.\n",
    "\n",
    "* Relevant: There has to be a measurable performance that can represent the relevance of a recommendation. On a ten-point scale, we would not want the estimated ratings to be \"off\" by more than certain point on the scale. For this we show the MAE, RMSE and Coverage aspects are better when compared to the baseline performance.\n",
    "\n",
    "* Exciting: We would want out recommendations to have an element of serendipity - indeed, a recommendation is more meaningfully relevant if it excites the user (which is the ultimate objective). This approach would require more data and we intend to enrich our data and attempt to factor in this requirement in Phase II of our project.\n",
    "\n",
    "We are trying to optimize on several parameters:\n",
    "\n",
    "* RMSE: It is important that the estimated ratings do not have a large variance to the extent that their relative rankings are affected. For this purpose, an ideal RMSE threshold has been fixed as mentioned above.\n",
    "* MAE: Along with optimal RMSE, we would also focus on optimizing MAE (Mean Absolute Error).\n",
    "* Serendipity: Although this is more subjective , it is a very important component in making a recommendation meaningfully relevant. We shall attempt to characterize, determine and measure this component in Phase II.\n",
    "* Coverage: We try out several hyperparameter tunings to get the desired coverage.\n",
    "\n",
    "In our pursuit to provide meaningfully relevant book recommendation to readers, we are willing to compromise on the following:\n",
    "\n",
    "* Absolute rating estimates: Below a certain threshold, our approach would not aim to improve absolute rating values. As mentioned before, for the algorithm, the relative rankings are more important and we aim to keep a control on this based on the defined RMSE threshold.\n",
    "* Right vs. correct: We would be ready to compromise correct recommendations for right recommendations. Correct recommendations would be the ones calculated without factoring in serendipity. Right recommendations might not include all the correct recommendations but would have a higher relevance. We aim to explore this factor more in Phase II.\n",
    "\n",
    "\n",
    "### Data Sets\n",
    "\n",
    "Our dataset is the taste profile dataset that is curated from a set of applications including the last fm dataset. The core dataset is the listen count of songs by user. User id, song id and listen count. It also has metadata available - the song name and the artist name. \n",
    "\n",
    "Other information about the songs is available for lookup via the million song dataset but for part 1 of the project, only the core dataset will be used.\n",
    "\n",
    "The core data is the Taste Profile Subset released by The Echo Nest as part of the Million Song Dataset. It consists of 48MM triplets (user ID, song ID, play count), 384K songs and over 1MM users.\n",
    "\n",
    "\n",
    "### Sampling of Data\n",
    "\n",
    "For this part of the homework, we kept the data set to be under 10,000 users and 10 songs as suggested in the instructions. This helped to gain a better understanding of the algorithms by running multiple iterations. Since there are 1.1MM users and 390K users in the original data, we first chose the top 10,000 users with the most songs. And then created a data set with the top 100 songs within this. This decreases the probability of randomly holding out the rating for an user who only listened to one song. After sampling the data is 11% dense.\n",
    "\n",
    "The sampling also maintains random seeds in case we need to replicate a run and can also specify new random seeds to get entirely new random data for cross-validations.\n",
    "\n",
    "### Cross Validation Methods\n",
    "\n",
    "The data was split by sampling user-song listen counts at random. We held out 20% for the test set and split the remainder of the 80% into training and validation - again using an 80-20 ratio. As the data was sampled at random, it is possible to have some users be part of only the test set. In such cases, we make use of the item-baseline predictions for the user\n",
    "\n",
    "\n",
    "## Neighborhood Based Approaches\n",
    "\n",
    "We had the option of \n",
    "\n",
    "Similarity Metrics\n",
    "\n",
    "Baseline Approaches\n",
    "\n",
    "\n",
    "## Model Based Approaches\n",
    "\n",
    "We have implemented two different types of algorithms using Matrix Factorization from Implicit and Non-negative Matrix Factorization (NMF) from Surprise.\n",
    "\n",
    "Please refer to the detailed analysis on Implicit ALS Matrix Factorization method in 'implicit_als.ipynb'. We covered the aspects of Cross Validation, hyper parameter tuning and Coverage metrics. Also shown are the affects of increasing factors on the RMSE and Coverage metrics. RMSE in this case has proven to be no significant value as the predictions tend to be around 0-1 range. Please refer to the detailed analysis on Implicit ALS Matrix Factorization method in 'implicit_als.ipynb'. \n",
    "\n",
    "We have also used an alternate approach using NMF from Surprise package. We have tried several approaches using this package, detailed results of which are in the notebook - 'surprise_nmf.ipynb'.\n",
    "\n",
    "* Reduced the listen_count using minmax scaler\n",
    "* Use the min and max of the listen count as a range\n",
    "* use Grid search to Cross Validate and evaluate the performance of various hyper parameters.\n",
    "* Perform the analysis on model performance with varying latent factors\n",
    "* Create the baseline performance using this package and compare the improvements\n",
    "* Measure the Scaling with increased sampling sizes\n",
    "\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
